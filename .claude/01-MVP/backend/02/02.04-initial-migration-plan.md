# Backend Task 02.04: Initial Migration - Implementation Plan

**Status**: Ready for Implementation
**Estimated Time**: 45-60 minutes
**Parent Task**: [02-database-design.md](./02-database-design.md)
**Dependencies**: ✅ Task 02.01, ✅ Task 02.02, ✅ Task 02.03

---

## Overview

Generate and apply the initial Alembic migration to create all database tables, PostgreSQL enum types, indexes, and constraints. This migration will establish the complete database schema for the Learn Greek Easy application with 8 tables and 4 custom enum types.

---

## Prerequisites Verification

Before starting, verify all prerequisites are met:

### Completed Prerequisites
- ✅ Task 02.01 (Database Connection & Session Management) - COMPLETED
- ✅ Task 02.02 (Define Database Models) - COMPLETED
- ✅ Task 02.03 (PostgreSQL Enums & Alembic Configuration) - COMPLETED
- ✅ Alembic initialized and configured with sync engine
- ✅ All 8 models detected by Alembic metadata
- ✅ All 4 enums detected and ready for migration

### Environment Checklist

```bash
# 1. Verify PostgreSQL Docker container is running
docker ps --filter "name=learn-greek"
# If not running: docker-compose up -d postgres

# 2. Verify Alembic configuration
cd learn-greek-easy-backend
poetry run python scripts/verify_alembic_config.py
# Expected: All 8 tables and 4 enums detected

# 3. Check current migration status
poetry run alembic current
# Expected: "No current revision" (fresh database)

# 4. Verify database connection
poetry run python -c "from src.config import settings; print('DB:', settings.database_url_sync[:30])"
# Expected: postgresql://postgres:...
```

---

## Implementation Steps

### Step 1: Start PostgreSQL Container (5 minutes)

**Objective**: Ensure PostgreSQL 16 is running and accessible

**Commands**:
```bash
# From project root
cd /Users/samosipov/Downloads/learn-greek-easy/learn-greek-easy-backend

# Start PostgreSQL container if not running
docker-compose up -d postgres

# Wait for PostgreSQL to be ready (5-10 seconds)
sleep 10

# Verify connection
docker exec learn-greek-postgres psql -U postgres -d learn_greek_easy -c "SELECT version();"
```

**Expected Output**:
```
PostgreSQL 16.x (Ubuntu 16.x-x)...
```

**Verification Checklist**:
- [ ] Container `learn-greek-postgres` is running
- [ ] Database `learn_greek_easy` exists
- [ ] Port 5432 is accessible
- [ ] No connection errors when testing psql

**Troubleshooting**:
- If container doesn't exist: Check `docker-compose.yml` configuration
- If database doesn't exist: It should be created automatically by init scripts
- If port conflict: Check if another PostgreSQL instance is using port 5432

---

### Step 2: Generate Initial Migration (10 minutes)

**Objective**: Create the first Alembic migration with autogenerate

**Command**:
```bash
cd /Users/samosipov/Downloads/learn-greek-easy/learn-greek-easy-backend

# Generate migration with descriptive message
poetry run alembic revision --autogenerate -m "Initial schema with users, decks, cards, progress, reviews"
```

**Expected Output**:
```
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.autogenerate.compare] Detected added table 'users'
INFO  [alembic.autogenerate.compare] Detected added table 'decks'
INFO  [alembic.autogenerate.compare] Detected added table 'cards'
INFO  [alembic.autogenerate.compare] Detected added table 'user_settings'
INFO  [alembic.autogenerate.compare] Detected added table 'refresh_tokens'
INFO  [alembic.autogenerate.compare] Detected added table 'user_deck_progress'
INFO  [alembic.autogenerate.compare] Detected added table 'card_statistics'
INFO  [alembic.autogenerate.compare] Detected added table 'reviews'
  Generating /path/to/alembic/versions/20251121_XXXX_initial_schema_with_users_decks_cards_progress_reviews.py ... done
```

**Generated File Location**:
```
alembic/versions/20251121_HHMM_<revision>_initial_schema_with_users_decks_cards_progress_reviews.py
```

**Verification Checklist**:
- [ ] Migration file created in `alembic/versions/`
- [ ] Filename includes timestamp and descriptive slug
- [ ] No errors during generation
- [ ] File size is reasonable (expect 200-400 lines)

---

### Step 3: Review Generated Migration File (15 minutes)

**Objective**: Manually inspect and validate the migration before applying

**File to Review**: `alembic/versions/<timestamp>_initial_schema_*.py`

#### 3.1: Check PostgreSQL Enum Types

Look for CREATE TYPE statements at the top of `upgrade()`:

```python
def upgrade() -> None:
    # Create PostgreSQL enum types
    sa.Enum('A1', 'A2', 'B1', 'B2', 'C1', 'C2', name='decklevel').create(op.get_bind())
    sa.Enum('easy', 'medium', 'hard', name='carddifficulty').create(op.get_bind())
    sa.Enum('new', 'learning', 'review', 'mastered', name='cardstatus').create(op.get_bind())
    sa.Enum(0, 1, 2, 3, 4, 5, name='reviewrating').create(op.get_bind())
```

**Check**:
- [ ] All 4 enum types are created: `decklevel`, `carddifficulty`, `cardstatus`, `reviewrating`
- [ ] DeckLevel has 6 values: A1, A2, B1, B2, C1, C2
- [ ] CardDifficulty has 3 values: easy, medium, hard
- [ ] CardStatus has 4 values: new, learning, review, mastered
- [ ] ReviewRating has 6 values: 0, 1, 2, 3, 4, 5

#### 3.2: Check Table Creation Order

Tables should be created in dependency order:

```python
# 1. Independent tables (no foreign keys)
op.create_table('users', ...)
op.create_table('decks', ...)

# 2. Tables with single foreign key
op.create_table('user_settings', ...)  # FK to users
op.create_table('refresh_tokens', ...)  # FK to users
op.create_table('cards', ...)  # FK to decks

# 3. Tables with multiple foreign keys
op.create_table('user_deck_progress', ...)  # FK to users, decks
op.create_table('card_statistics', ...)  # FK to users, cards
op.create_table('reviews', ...)  # FK to users, cards
```

**Check**:
- [ ] Tables created in correct order (respect foreign keys)
- [ ] All 8 tables present

#### 3.3: Verify UUID Primary Keys

Each table should have UUID primary key with server default:

```python
sa.Column('id', sa.UUID(), server_default=sa.text('uuid_generate_v4()'), nullable=False)
sa.PrimaryKeyConstraint('id')
```

**Check**:
- [ ] All tables use UUID for primary key
- [ ] `server_default=sa.text('uuid_generate_v4()')` present
- [ ] Primary key constraint defined

#### 3.4: Check Critical Columns

**Users table**:
```python
op.create_table('users',
    sa.Column('id', sa.UUID(), ...),
    sa.Column('email', sa.String(length=255), nullable=False),
    sa.Column('password_hash', sa.String(length=255), nullable=True),
    sa.Column('full_name', sa.String(length=255), nullable=True),
    sa.Column('is_active', sa.Boolean(), nullable=False),
    sa.Column('is_superuser', sa.Boolean(), nullable=False),
    sa.Column('email_verified_at', sa.DateTime(timezone=True), nullable=True),
    sa.Column('google_id', sa.String(length=255), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
)
```

**Check**:
- [ ] `password_hash` is nullable (for Google OAuth users)
- [ ] `google_id` is nullable (for email/password users)
- [ ] `email_verified_at` is timezone-aware DateTime
- [ ] `created_at` and `updated_at` have `server_default=now()`

**Decks table**:
```python
op.create_table('decks',
    sa.Column('id', sa.UUID(), ...),
    sa.Column('name', sa.String(length=255), nullable=False),
    sa.Column('description', sa.Text(), nullable=True),
    sa.Column('level', sa.Enum(..., name='decklevel'), nullable=False),
    sa.Column('is_active', sa.Boolean(), nullable=False),
    sa.Column('created_at', sa.DateTime(timezone=True), ...),
    sa.Column('updated_at', sa.DateTime(timezone=True), ...),
)
```

**Check**:
- [ ] `level` uses `decklevel` enum type
- [ ] `description` is Text (not String)
- [ ] `is_active` defaults to True

**Cards table**:
```python
op.create_table('cards',
    sa.Column('id', sa.UUID(), ...),
    sa.Column('deck_id', sa.UUID(), nullable=False),
    sa.Column('front_text', sa.Text(), nullable=False),  # Greek
    sa.Column('back_text', sa.Text(), nullable=False),  # English
    sa.Column('example_sentence', sa.Text(), nullable=True),
    sa.Column('pronunciation', sa.String(length=255), nullable=True),
    sa.Column('difficulty', sa.Enum(..., name='carddifficulty'), nullable=False),
    sa.Column('order_index', sa.Integer(), nullable=False),
    sa.ForeignKeyConstraint(['deck_id'], ['decks.id'], ondelete='CASCADE'),
)
```

**Check**:
- [ ] `front_text` and `back_text` are Text (for Greek characters)
- [ ] `difficulty` uses `carddifficulty` enum
- [ ] Foreign key to `decks.id` with `ondelete='CASCADE'`

**CardStatistics table** (SM-2 algorithm):
```python
op.create_table('card_statistics',
    sa.Column('id', sa.UUID(), ...),
    sa.Column('user_id', sa.UUID(), nullable=False),
    sa.Column('card_id', sa.UUID(), nullable=False),
    sa.Column('easiness_factor', sa.Float(), nullable=False),  # SM-2: default 2.5
    sa.Column('interval', sa.Integer(), nullable=False),  # Days, default 0
    sa.Column('repetitions', sa.Integer(), nullable=False),  # Default 0
    sa.Column('next_review_date', sa.Date(), server_default=sa.text('current_date()'), nullable=False),
    sa.Column('status', sa.Enum(..., name='cardstatus'), nullable=False),
    sa.ForeignKeyConstraint(['user_id'], ['users.id'], ondelete='CASCADE'),
    sa.ForeignKeyConstraint(['card_id'], ['cards.id'], ondelete='CASCADE'),
    sa.UniqueConstraint('user_id', 'card_id', name='uq_user_card'),
)
```

**Check**:
- [ ] SM-2 fields present: `easiness_factor`, `interval`, `repetitions`
- [ ] `next_review_date` is Date type with `server_default=current_date()`
- [ ] `status` uses `cardstatus` enum
- [ ] Unique constraint on `(user_id, card_id)`
- [ ] Both foreign keys have `ondelete='CASCADE'`

**Reviews table**:
```python
op.create_table('reviews',
    sa.Column('id', sa.UUID(), ...),
    sa.Column('user_id', sa.UUID(), nullable=False),
    sa.Column('card_id', sa.UUID(), nullable=False),
    sa.Column('quality', sa.Enum(..., name='reviewrating'), nullable=False),  # 0-5
    sa.Column('time_taken', sa.Integer(), nullable=True),  # Seconds
    sa.Column('reviewed_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.ForeignKeyConstraint(['user_id'], ['users.id'], ondelete='CASCADE'),
    sa.ForeignKeyConstraint(['card_id'], ['cards.id'], ondelete='CASCADE'),
)
```

**Check**:
- [ ] `quality` uses `reviewrating` enum (0-5)
- [ ] `time_taken` is Integer (seconds)
- [ ] `reviewed_at` has `server_default=now()`

#### 3.5: Check Indexes

Look for `op.create_index()` statements:

**Expected Indexes**:

```python
# Users table
op.create_index(op.f('ix_users_email'), 'users', ['email'], unique=True)
op.create_index(op.f('ix_users_google_id'), 'users', ['google_id'], unique=False)

# Decks table
op.create_index(op.f('ix_decks_level'), 'decks', ['level'], unique=False)
op.create_index(op.f('ix_decks_is_active'), 'decks', ['is_active'], unique=False)
op.create_index(op.f('ix_decks_name'), 'decks', ['name'], unique=False)

# Cards table
op.create_index(op.f('ix_cards_deck_id'), 'cards', ['deck_id'], unique=False)
op.create_index(op.f('ix_cards_difficulty'), 'cards', ['difficulty'], unique=False)

# UserDeckProgress table
op.create_index(op.f('ix_user_deck_progress_user_id'), 'user_deck_progress', ['user_id'], unique=False)
op.create_index(op.f('ix_user_deck_progress_deck_id'), 'user_deck_progress', ['deck_id'], unique=False)

# CardStatistics table (CRITICAL for performance)
op.create_index(op.f('ix_card_statistics_user_id'), 'card_statistics', ['user_id'], unique=False)
op.create_index(op.f('ix_card_statistics_card_id'), 'card_statistics', ['card_id'], unique=False)
op.create_index(op.f('ix_card_statistics_next_review_date'), 'card_statistics', ['next_review_date'], unique=False)
op.create_index(op.f('ix_card_statistics_status'), 'card_statistics', ['status'], unique=False)

# Composite index for "get due cards" query
op.create_index(
    'ix_card_statistics_user_due_cards',
    'card_statistics',
    ['user_id', 'next_review_date', 'status'],
    unique=False
)

# RefreshTokens table
op.create_index(op.f('ix_refresh_tokens_token'), 'refresh_tokens', ['token'], unique=True)
op.create_index(op.f('ix_refresh_tokens_expires_at'), 'refresh_tokens', ['expires_at'], unique=False)

# Reviews table
op.create_index(op.f('ix_reviews_user_id'), 'reviews', ['user_id'], unique=False)
op.create_index(op.f('ix_reviews_card_id'), 'reviews', ['card_id'], unique=False)
op.create_index(op.f('ix_reviews_reviewed_at'), 'reviews', ['reviewed_at'], unique=False)
```

**Check**:
- [ ] All foreign key columns are indexed
- [ ] Unique indexes on email and token columns
- [ ] `next_review_date` indexed (critical for SRS queries)
- [ ] `status` indexed for filtering cards by learning status
- [ ] Composite index for "get due cards" query (user_id + next_review_date + status)

**Manual Addition Required?**:

If the composite index is missing, add it manually before the `# ### end Alembic commands ###` line:

```python
def upgrade() -> None:
    # ... existing table creation ...

    # Add composite index for efficient "due cards" queries
    op.create_index(
        'ix_card_statistics_user_due_cards',
        'card_statistics',
        ['user_id', 'next_review_date', 'status'],
        unique=False
    )

    # ### end Alembic commands ###
```

And in `downgrade()`:

```python
def downgrade() -> None:
    # ### commands auto generated by Alembic ###

    # Remove composite index
    op.drop_index('ix_card_statistics_user_due_cards', table_name='card_statistics')

    # ... rest of downgrade ...
```

#### 3.6: Check Downgrade Function

Verify the `downgrade()` function drops everything in reverse order:

```python
def downgrade() -> None:
    # Drop tables in reverse order (respect foreign keys)
    op.drop_table('reviews')
    op.drop_table('card_statistics')
    op.drop_table('user_deck_progress')
    op.drop_table('cards')
    op.drop_table('refresh_tokens')
    op.drop_table('user_settings')
    op.drop_table('decks')
    op.drop_table('users')

    # Drop enum types
    sa.Enum(name='reviewrating').drop(op.get_bind())
    sa.Enum(name='cardstatus').drop(op.get_bind())
    sa.Enum(name='carddifficulty').drop(op.get_bind())
    sa.Enum(name='decklevel').drop(op.get_bind())
```

**Check**:
- [ ] Tables dropped in reverse order
- [ ] Enum types dropped after tables
- [ ] No syntax errors

---

### Step 4: Apply Migration (5 minutes)

**Objective**: Execute the migration to create the database schema

**Command**:
```bash
cd /Users/samosipov/Downloads/learn-greek-easy/learn-greek-easy-backend

# Apply migration
poetry run alembic upgrade head
```

**Expected Output**:
```
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running upgrade  -> <revision_id>, Initial schema with users, decks, cards, progress, reviews
```

**Verification**:
```bash
# Check migration status
poetry run alembic current

# Expected output:
# <revision_id> (head)
```

**Check**:
- [ ] Migration applies without errors
- [ ] `alembic current` shows the new revision
- [ ] No PostgreSQL errors in output

---

### Step 5: Verify Database Schema (15 minutes)

**Objective**: Confirm all tables, enums, indexes, and constraints were created correctly

#### 5.1: Verify Tables

**SQL Query**:
```sql
-- Connect to database
docker exec -it learn-greek-postgres psql -U postgres -d learn_greek_easy

-- List all tables
SELECT table_name, table_type
FROM information_schema.tables
WHERE table_schema = 'public'
ORDER BY table_name;
```

**Expected Output**:
```
       table_name       | table_type
------------------------+------------
 alembic_version        | BASE TABLE
 card_statistics        | BASE TABLE
 cards                  | BASE TABLE
 decks                  | BASE TABLE
 refresh_tokens         | BASE TABLE
 reviews                | BASE TABLE
 user_deck_progress     | BASE TABLE
 user_settings          | BASE TABLE
 users                  | BASE TABLE
(9 rows)
```

**Check**:
- [ ] All 8 application tables exist
- [ ] `alembic_version` table exists (migration tracking)

#### 5.2: Verify PostgreSQL Enum Types

**SQL Query**:
```sql
-- List all enum types
SELECT
    t.typname AS enum_name,
    array_agg(e.enumlabel ORDER BY e.enumsortorder) AS enum_values
FROM pg_type t
JOIN pg_enum e ON t.oid = e.enumtypid
WHERE t.typname IN ('decklevel', 'carddifficulty', 'cardstatus', 'reviewrating')
GROUP BY t.typname
ORDER BY t.typname;
```

**Expected Output**:
```
   enum_name    |                enum_values
----------------+-------------------------------------------
 carddifficulty | {easy,medium,hard}
 cardstatus     | {new,learning,review,mastered}
 decklevel      | {A1,A2,B1,B2,C1,C2}
 reviewrating   | {0,1,2,3,4,5}
(4 rows)
```

**Check**:
- [ ] `decklevel` has 6 values: A1, A2, B1, B2, C1, C2
- [ ] `carddifficulty` has 3 values: easy, medium, hard
- [ ] `cardstatus` has 4 values: new, learning, review, mastered
- [ ] `reviewrating` has 6 values: 0, 1, 2, 3, 4, 5

#### 5.3: Verify Table Structures

**SQL Query for Users Table**:
```sql
-- Describe users table
\d users
```

**Expected Output** (key columns):
```
Column             |           Type                | Nullable |   Default
-------------------+-------------------------------+----------+-------------------
id                 | uuid                          | not null | uuid_generate_v4()
email              | character varying(255)        | not null |
password_hash      | character varying(255)        |          |
google_id          | character varying(255)        |          |
is_active          | boolean                       | not null |
created_at         | timestamp with time zone      | not null | now()
updated_at         | timestamp with time zone      | not null | now()
```

**SQL Query for CardStatistics Table**:
```sql
\d card_statistics
```

**Expected Output** (key SM-2 columns):
```
Column             |           Type       | Nullable |   Default
-------------------+----------------------+----------+-------------------
easiness_factor    | double precision     | not null |
interval           | integer              | not null |
repetitions        | integer              | not null |
next_review_date   | date                 | not null | current_date()
status             | cardstatus           | not null |
```

**Check**:
- [ ] UUID columns use `uuid` type
- [ ] Enum columns use correct enum types
- [ ] Timestamps are `timestamp with time zone`
- [ ] Server defaults are set correctly

#### 5.4: Verify Indexes

**SQL Query**:
```sql
-- List all indexes
SELECT
    schemaname,
    tablename,
    indexname,
    indexdef
FROM pg_indexes
WHERE schemaname = 'public'
ORDER BY tablename, indexname;
```

**Expected Indexes (partial list)**:
```
ix_users_email                        -- UNIQUE
ix_users_google_id
ix_decks_level
ix_decks_is_active
ix_cards_deck_id
ix_card_statistics_user_id
ix_card_statistics_next_review_date   -- CRITICAL for SRS
ix_card_statistics_status
ix_card_statistics_user_due_cards     -- Composite (user_id, next_review_date, status)
ix_refresh_tokens_token               -- UNIQUE
```

**Check**:
- [ ] All foreign keys are indexed
- [ ] `next_review_date` has index
- [ ] Composite index exists for due cards query
- [ ] Unique indexes on email and token

**Count Verification**:
```sql
-- Count indexes per table
SELECT
    tablename,
    COUNT(*) as index_count
FROM pg_indexes
WHERE schemaname = 'public' AND tablename != 'alembic_version'
GROUP BY tablename
ORDER BY tablename;
```

**Expected Counts**:
```
tablename           | index_count
--------------------+-------------
card_statistics     | 5-6  (including composite)
cards               | 3-4
decks               | 4-5
refresh_tokens      | 3-4
reviews             | 4-5
user_deck_progress  | 4-5
user_settings       | 2-3
users               | 3-4
```

#### 5.5: Verify Foreign Key Constraints

**SQL Query**:
```sql
-- List all foreign key constraints
SELECT
    tc.table_name,
    kcu.column_name,
    ccu.table_name AS foreign_table_name,
    ccu.column_name AS foreign_column_name,
    rc.delete_rule
FROM information_schema.table_constraints AS tc
JOIN information_schema.key_column_usage AS kcu
    ON tc.constraint_name = kcu.constraint_name
JOIN information_schema.constraint_column_usage AS ccu
    ON ccu.constraint_name = tc.constraint_name
JOIN information_schema.referential_constraints AS rc
    ON tc.constraint_name = rc.constraint_name
WHERE tc.constraint_type = 'FOREIGN KEY'
ORDER BY tc.table_name, kcu.column_name;
```

**Expected Foreign Keys**:
```
table_name          | column_name | foreign_table_name | delete_rule
--------------------+-------------+--------------------+-------------
card_statistics     | user_id     | users              | CASCADE
card_statistics     | card_id     | cards              | CASCADE
cards               | deck_id     | decks              | CASCADE
refresh_tokens      | user_id     | users              | CASCADE
reviews             | user_id     | users              | CASCADE
reviews             | card_id     | cards              | CASCADE
user_deck_progress  | user_id     | users              | CASCADE
user_deck_progress  | deck_id     | decks              | CASCADE
user_settings       | user_id     | users              | CASCADE
```

**Check**:
- [ ] All foreign keys have `CASCADE` delete rule
- [ ] Foreign keys reference correct tables
- [ ] All relationships are present

#### 5.6: Verify Unique Constraints

**SQL Query**:
```sql
-- List unique constraints
SELECT
    tc.table_name,
    tc.constraint_name,
    array_agg(kcu.column_name ORDER BY kcu.ordinal_position) AS columns
FROM information_schema.table_constraints AS tc
JOIN information_schema.key_column_usage AS kcu
    ON tc.constraint_name = kcu.constraint_name
WHERE tc.constraint_type = 'UNIQUE'
    AND tc.table_schema = 'public'
GROUP BY tc.table_name, tc.constraint_name
ORDER BY tc.table_name;
```

**Expected Unique Constraints**:
```
table_name          | constraint_name        | columns
--------------------+------------------------+------------------
card_statistics     | uq_user_card           | {user_id,card_id}
refresh_tokens      | ix_refresh_tokens_token| {token}
user_deck_progress  | uq_user_deck           | {user_id,deck_id}
user_settings       | user_settings_user_id_key | {user_id}
users               | ix_users_email         | {email}
```

**Check**:
- [ ] `users.email` is unique
- [ ] `card_statistics(user_id, card_id)` unique constraint
- [ ] `user_deck_progress(user_id, deck_id)` unique constraint
- [ ] `user_settings.user_id` unique (one-to-one)
- [ ] `refresh_tokens.token` unique

---

### Step 6: Test Rollback (Downgrade) (5 minutes)

**Objective**: Verify the migration can be safely rolled back

**Commands**:
```bash
cd /Users/samosipov/Downloads/learn-greek-easy/learn-greek-easy-backend

# Downgrade to previous version (base)
poetry run alembic downgrade -1

# Verify tables are dropped
docker exec -it learn-greek-postgres psql -U postgres -d learn_greek_easy -c "\dt"

# Re-apply migration
poetry run alembic upgrade head

# Verify tables are back
docker exec -it learn-greek-postgres psql -U postgres -d learn_greek_easy -c "\dt"
```

**Expected Behavior**:
1. **After downgrade**: Only `alembic_version` table should exist
2. **After re-upgrade**: All 8 tables + `alembic_version` should exist

**Check**:
- [ ] Downgrade completes without errors
- [ ] All tables dropped (except alembic_version)
- [ ] Enum types dropped
- [ ] Upgrade works after downgrade
- [ ] Schema is identical after re-upgrade

**Verification SQL**:
```sql
-- After downgrade, verify enums are gone
SELECT typname FROM pg_type WHERE typname IN ('decklevel', 'carddifficulty', 'cardstatus', 'reviewrating');
-- Expected: 0 rows
```

---

### Step 7: Create Verification Script (5 minutes)

**Objective**: Automated verification of migration success

**File**: `scripts/verify_migration.py`

**Content**:
```python
"""Verify initial migration was applied correctly."""
import asyncio
import sys
from pathlib import Path

# Add parent directory to path
sys.path.insert(0, str(Path(__file__).parent.parent))

from sqlalchemy import text
from src.db.session import engine


async def verify_migration():
    """Run comprehensive migration verification."""
    print("=" * 60)
    print("MIGRATION VERIFICATION")
    print("=" * 60)

    errors = []

    try:
        async with engine.begin() as conn:
            # Check 1: Verify tables
            print("\n1. Verifying Tables...")
            result = await conn.execute(text("""
                SELECT table_name
                FROM information_schema.tables
                WHERE table_schema = 'public'
                AND table_type = 'BASE TABLE'
                AND table_name != 'alembic_version'
                ORDER BY table_name
            """))
            tables = [row[0] for row in result]

            expected_tables = [
                'card_statistics', 'cards', 'decks', 'refresh_tokens',
                'reviews', 'user_deck_progress', 'user_settings', 'users'
            ]

            if set(tables) == set(expected_tables):
                print(f"   ✅ All {len(expected_tables)} tables exist")
                for table in tables:
                    print(f"      - {table}")
            else:
                missing = set(expected_tables) - set(tables)
                extra = set(tables) - set(expected_tables)
                if missing:
                    print(f"   ❌ Missing tables: {missing}")
                    errors.append(f"Missing tables: {missing}")
                if extra:
                    print(f"   ⚠️  Extra tables: {extra}")

            # Check 2: Verify enums
            print("\n2. Verifying PostgreSQL Enum Types...")
            result = await conn.execute(text("""
                SELECT t.typname, array_agg(e.enumlabel ORDER BY e.enumsortorder)
                FROM pg_type t
                JOIN pg_enum e ON t.oid = e.enumtypid
                WHERE t.typname IN ('decklevel', 'carddifficulty', 'cardstatus', 'reviewrating')
                GROUP BY t.typname
                ORDER BY t.typname
            """))
            enums = {row[0]: row[1] for row in result}

            expected_enums = {
                'decklevel': ['A1', 'A2', 'B1', 'B2', 'C1', 'C2'],
                'carddifficulty': ['easy', 'medium', 'hard'],
                'cardstatus': ['new', 'learning', 'review', 'mastered'],
                'reviewrating': ['0', '1', '2', '3', '4', '5'],
            }

            for enum_name, expected_values in expected_enums.items():
                if enum_name in enums:
                    # Convert to strings for comparison
                    actual_values = [str(v) for v in enums[enum_name]]
                    if actual_values == expected_values:
                        print(f"   ✅ {enum_name}: {len(expected_values)} values")
                    else:
                        print(f"   ❌ {enum_name}: Expected {expected_values}, got {actual_values}")
                        errors.append(f"Enum {enum_name} mismatch")
                else:
                    print(f"   ❌ {enum_name}: NOT FOUND")
                    errors.append(f"Missing enum: {enum_name}")

            # Check 3: Verify critical indexes
            print("\n3. Verifying Critical Indexes...")
            result = await conn.execute(text("""
                SELECT indexname
                FROM pg_indexes
                WHERE schemaname = 'public'
                AND tablename = 'card_statistics'
                AND indexname LIKE '%next_review_date%'
            """))
            indexes = [row[0] for row in result]

            if indexes:
                print(f"   ✅ next_review_date index exists: {indexes[0]}")
            else:
                print(f"   ❌ next_review_date index MISSING")
                errors.append("Missing critical index: next_review_date")

            # Check 4: Verify foreign keys
            print("\n4. Verifying Foreign Key Constraints...")
            result = await conn.execute(text("""
                SELECT COUNT(*)
                FROM information_schema.table_constraints
                WHERE constraint_type = 'FOREIGN KEY'
                AND table_schema = 'public'
            """))
            fk_count = result.scalar()

            expected_fk_count = 9  # cards(1), user_settings(1), refresh_tokens(1),
                                   # user_deck_progress(2), card_statistics(2), reviews(2)

            if fk_count == expected_fk_count:
                print(f"   ✅ All {expected_fk_count} foreign keys exist")
            else:
                print(f"   ⚠️  Found {fk_count} foreign keys, expected {expected_fk_count}")

            # Check 5: Verify unique constraints
            print("\n5. Verifying Unique Constraints...")
            result = await conn.execute(text("""
                SELECT tc.table_name, tc.constraint_name
                FROM information_schema.table_constraints AS tc
                WHERE tc.constraint_type = 'UNIQUE'
                AND tc.table_schema = 'public'
                ORDER BY tc.table_name
            """))
            unique_constraints = list(result)

            print(f"   ✅ Found {len(unique_constraints)} unique constraints")

            # Check for critical unique constraints
            result = await conn.execute(text("""
                SELECT constraint_name
                FROM information_schema.table_constraints
                WHERE constraint_type = 'UNIQUE'
                AND table_name = 'card_statistics'
                AND constraint_name = 'uq_user_card'
            """))
            if result.scalar():
                print(f"   ✅ card_statistics(user_id, card_id) unique constraint exists")
            else:
                print(f"   ❌ card_statistics unique constraint MISSING")
                errors.append("Missing unique constraint: uq_user_card")

            # Check 6: Verify alembic version
            print("\n6. Verifying Alembic Migration Status...")
            result = await conn.execute(text("SELECT version_num FROM alembic_version"))
            version = result.scalar()

            if version:
                print(f"   ✅ Current migration: {version}")
            else:
                print(f"   ❌ No migration version found")
                errors.append("No alembic version")

    finally:
        await engine.dispose()

    # Summary
    print("\n" + "=" * 60)
    if not errors:
        print("✅ MIGRATION VERIFICATION PASSED")
        print("=" * 60)
        return True
    else:
        print("❌ MIGRATION VERIFICATION FAILED")
        print("\nErrors:")
        for error in errors:
            print(f"  - {error}")
        print("=" * 60)
        return False


if __name__ == "__main__":
    try:
        success = asyncio.run(verify_migration())
        sys.exit(0 if success else 1)
    except Exception as e:
        print(f"\n❌ ERROR: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
```

**Run Verification**:
```bash
cd /Users/samosipov/Downloads/learn-greek-easy/learn-greek-easy-backend
poetry run python scripts/verify_migration.py
```

**Expected Output**:
```
============================================================
MIGRATION VERIFICATION
============================================================

1. Verifying Tables...
   ✅ All 8 tables exist
      - card_statistics
      - cards
      - decks
      - refresh_tokens
      - reviews
      - user_deck_progress
      - user_settings
      - users

2. Verifying PostgreSQL Enum Types...
   ✅ carddifficulty: 3 values
   ✅ cardstatus: 4 values
   ✅ decklevel: 6 values
   ✅ reviewrating: 6 values

3. Verifying Critical Indexes...
   ✅ next_review_date index exists: ix_card_statistics_next_review_date

4. Verifying Foreign Key Constraints...
   ✅ All 9 foreign keys exist

5. Verifying Unique Constraints...
   ✅ Found 5 unique constraints
   ✅ card_statistics(user_id, card_id) unique constraint exists

6. Verifying Alembic Migration Status...
   ✅ Current migration: <revision_id>

============================================================
✅ MIGRATION VERIFICATION PASSED
============================================================
```

---

## Success Criteria

### Functional Requirements
- [ ] Initial migration generated successfully
- [ ] All 8 tables created in database
- [ ] All 4 PostgreSQL enum types created with correct values
- [ ] UUID primary keys with server_default on all tables
- [ ] All foreign keys with CASCADE delete behavior
- [ ] Unique constraints on (user_id, card_id) and (user_id, deck_id)
- [ ] All timestamps are timezone-aware
- [ ] Migration can be rolled back cleanly

### Index Requirements
- [ ] All foreign key columns indexed
- [ ] `users.email` has unique index
- [ ] `refresh_tokens.token` has unique index
- [ ] `card_statistics.next_review_date` indexed (critical for SRS)
- [ ] `card_statistics.status` indexed
- [ ] Composite index for due cards query (optional but recommended)

### Data Integrity
- [ ] All NOT NULL constraints enforced
- [ ] Server defaults work (uuid_generate_v4(), now(), current_date())
- [ ] Enum values match model definitions
- [ ] Foreign key relationships prevent orphaned records

### Verification
- [ ] `alembic current` shows migration version
- [ ] `scripts/verify_migration.py` passes all checks
- [ ] Manual SQL queries confirm schema correctness
- [ ] Rollback test succeeds

---

## Common Issues and Solutions

### Issue 1: "uuid_generate_v4() function not found"
**Cause**: PostgreSQL uuid-ossp extension not enabled
**Solution**:
```sql
docker exec -it learn-greek-postgres psql -U postgres -d learn_greek_easy -c "CREATE EXTENSION IF NOT EXISTS \"uuid-ossp\";"
```

### Issue 2: Enum types already exist
**Cause**: Previous migration attempt failed partially
**Solution**:
```sql
-- Drop existing enum types
DROP TYPE IF EXISTS decklevel CASCADE;
DROP TYPE IF EXISTS carddifficulty CASCADE;
DROP TYPE IF EXISTS cardstatus CASCADE;
DROP TYPE IF EXISTS reviewrating CASCADE;

-- Re-run migration
poetry run alembic upgrade head
```

### Issue 3: Tables already exist
**Cause**: Database has existing tables
**Solution**:
```bash
# Option 1: Drop and recreate database
docker exec -it learn-greek-postgres psql -U postgres -c "DROP DATABASE learn_greek_easy;"
docker exec -it learn-greek-postgres psql -U postgres -c "CREATE DATABASE learn_greek_easy;"

# Option 2: Stamp existing schema (if schema matches)
poetry run alembic stamp head
```

### Issue 4: Migration generates duplicate indexes
**Cause**: SQLAlchemy creating indexes from `index=True` and relationships
**Solution**: Review generated migration, remove duplicate `op.create_index()` calls

### Issue 5: Foreign key constraint violation during downgrade
**Cause**: Data exists in tables with foreign keys
**Solution**: Ensure test database is empty before downgrade testing

### Issue 6: Alembic can't import models
**Cause**: Python path issue
**Solution**: Run alembic from project root, ensure `PYTHONPATH` includes project directory

---

## Performance Considerations

### Critical Indexes for Production

The following indexes are CRITICAL for performance and should be verified:

1. **Due Cards Query** (most frequent query):
```sql
CREATE INDEX ix_card_statistics_user_due_cards
ON card_statistics (user_id, next_review_date, status);
```
This composite index enables fast retrieval of cards due for review.

2. **Next Review Date** (SRS algorithm):
```sql
CREATE INDEX ix_card_statistics_next_review_date
ON card_statistics (next_review_date);
```

3. **User's Cards**:
```sql
CREATE INDEX ix_card_statistics_user_id
ON card_statistics (user_id);
```

4. **Email Login**:
```sql
CREATE UNIQUE INDEX ix_users_email ON users (email);
```

### Query Performance Testing

After migration, test these critical queries:

```sql
-- Query 1: Get due cards for user (should use composite index)
EXPLAIN ANALYZE
SELECT cs.*, c.front_text, c.back_text
FROM card_statistics cs
JOIN cards c ON cs.card_id = c.id
WHERE cs.user_id = 'some-uuid'
  AND cs.next_review_date <= CURRENT_DATE
  AND cs.status IN ('new', 'learning', 'review')
ORDER BY cs.next_review_date
LIMIT 20;

-- Query 2: User deck progress (should use indexes)
EXPLAIN ANALYZE
SELECT d.*, udp.cards_studied, udp.cards_mastered
FROM decks d
LEFT JOIN user_deck_progress udp ON d.id = udp.deck_id AND udp.user_id = 'some-uuid'
WHERE d.is_active = true
ORDER BY d.level;

-- Query 3: User login (should use unique index)
EXPLAIN ANALYZE
SELECT * FROM users WHERE email = 'test@example.com';
```

**Expected**: All queries should use indexes (no "Seq Scan" in EXPLAIN output)

---

## Estimated Effort Breakdown

| Step | Task | Duration |
|------|------|----------|
| 1 | Start PostgreSQL container | 5 min |
| 2 | Generate initial migration | 10 min |
| 3 | Review generated migration file | 15 min |
| 4 | Apply migration | 5 min |
| 5 | Verify database schema | 15 min |
| 6 | Test rollback | 5 min |
| 7 | Create verification script | 5 min |
| **TOTAL** | | **60 min** |

---

## File Structure After Completion

```
learn-greek-easy-backend/
├── alembic/
│   ├── versions/
│   │   └── 20251121_HHMM_<revision>_initial_schema_with_users_decks_cards_progress_reviews.py  # ✅ NEW
│   ├── env.py                 # ✅ Already configured
│   └── script.py.mako         # ✅ Already configured
├── alembic.ini                # ✅ Already configured
├── scripts/
│   ├── verify_alembic_config.py  # ✅ From task 02.03
│   └── verify_migration.py    # ✅ NEW - Migration verification
├── src/
│   └── db/
│       ├── models.py          # ✅ Already complete
│       ├── base.py            # ✅ Already complete
│       └── session.py         # ✅ Already complete
└── .env                       # ✅ Already configured
```

---

## Next Steps (Task 02.05)

After completing this task:

1. **Task 02.05: Create Pydantic Schemas**
   - Define request/response schemas for all models
   - Implement validation logic
   - Create schema exports from `src/schemas/`
   - Estimated time: 45-60 minutes

2. **Task 02.06: Seed Initial Data** (Optional)
   - Create seed script for sample decks and cards
   - Load Greek vocabulary data
   - Create test users

---

## Key Takeaways

1. **Autogenerate is Smart**: Alembic detects models, enums, indexes, and constraints
2. **Always Review**: Generated migrations may need manual adjustments
3. **Indexes Matter**: Composite indexes for common queries improve performance significantly
4. **Test Rollback**: Always verify downgrade works before production
5. **Verify Everything**: Automated verification catches issues early
6. **UUID Extension**: PostgreSQL needs uuid-ossp extension for server-side UUID generation
7. **Cascade Deletes**: CASCADE ensures referential integrity when deleting users/decks

---

**Document Version**: 1.0
**Created**: 2025-11-21
**Status**: Ready for Implementation
**Dependencies**: Tasks 02.01 ✅, 02.02 ✅, 02.03 ✅
**Next Task**: 02.05 (Create Pydantic Schemas)

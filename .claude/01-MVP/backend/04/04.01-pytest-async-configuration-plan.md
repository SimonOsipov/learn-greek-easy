# Subtask 04.01: Configure Pytest with Async Support - Detailed Implementation Plan

**Document Version**: 1.1
**Created**: 2025-11-29
**Completed**: 2025-11-30
**Status**: ✅ COMPLETED
**Actual Duration**: ~45 minutes
**Priority**: Critical (Foundation for all backend testing)
**Dependencies**: Task 02 (Database Models), Task 03 (Authentication)

---

## Table of Contents

1. [Overview](#overview)
2. [Prerequisites Verification](#prerequisites-verification)
3. [Step-by-Step Implementation](#step-by-step-implementation)
4. [Testing Instructions](#testing-instructions)
5. [Validation Checklist](#validation-checklist)
6. [Troubleshooting Guide](#troubleshooting-guide)
7. [Technical Considerations](#technical-considerations)
8. [Next Steps](#next-steps)

---

## Overview

### Objective
Configure pytest with full async support using pytest-asyncio, establishing the foundation for testing all async FastAPI endpoints, SQLAlchemy async operations, and background tasks.

### What You'll Build

**Configuration Files**:
1. `pyproject.toml` - Pytest configuration section
2. `tests/conftest.py` - Global fixtures and event loop setup

**Key Configurations**:
- pytest-asyncio in "auto" mode (automatic async test detection)
- Custom event loop fixture for session scope
- Test markers (unit, integration, slow, auth)
- Async-compatible test discovery
- Filter warnings for clean output

### Success Criteria
- [x] All existing tests continue to pass
- [x] Async tests run automatically without `@pytest.mark.asyncio` decorator
- [x] Event loop properly scoped and cleaned up
- [x] Test markers available for filtering (unit, integration, slow, auth, api, db)
- [x] No deprecation warnings from pytest-asyncio

### Current State Analysis

**Existing pytest configuration** (minimal):
```toml
# pyproject.toml (current)
[tool.poetry.dev-dependencies]
pytest = "^8.0"
pytest-asyncio = "^0.23"
pytest-cov = "^4.1"
```

**Existing test structure**:
```
tests/
├── conftest.py              # Basic fixtures (needs enhancement)
├── unit/
│   ├── test_security.py     # 35 tests
│   ├── test_jwt_tokens.py   # 28 tests
│   ├── test_dependencies.py # 21 tests
│   ├── test_auth_service_refresh.py  # 11 tests
│   ├── test_auth_service_sessions.py # 12 tests
│   └── middleware/
│       └── test_auth_middleware.py   # 42 tests
└── integration/
    └── (empty)
```

**Total existing tests**: ~149 tests

---

## Prerequisites Verification

### Step 1: Verify Dependencies Are Installed

Run this command to check pytest and pytest-asyncio:

```bash
cd /Users/samosipov/Downloads/learn-greek-easy/learn-greek-easy-backend && /Users/samosipov/.local/bin/poetry show | grep -E "(pytest|asyncio)"
```

**Expected Output**:
```
pytest            8.x.x  pytest: simple powerful testing with Python
pytest-asyncio    0.23.x pytest support for asyncio
pytest-cov        4.1.x  Pytest plugin for measuring coverage
```

**If dependencies are missing**, run:
```bash
cd /Users/samosipov/Downloads/learn-greek-easy/learn-greek-easy-backend && /Users/samosipov/.local/bin/poetry add pytest pytest-asyncio pytest-cov --group dev
```

### Step 2: Check Existing Test Count

Verify current tests pass before making changes:

```bash
cd /Users/samosipov/Downloads/learn-greek-easy/learn-greek-easy-backend && /Users/samosipov/.local/bin/poetry run pytest --collect-only -q
```

**Expected**: Should show ~149 tests collected

### Step 3: Verify Python Version

```bash
cd /Users/samosipov/Downloads/learn-greek-easy/learn-greek-easy-backend && /Users/samosipov/.local/bin/poetry run python --version
```

**Expected**: Python 3.14.x

### Step 4: Check Existing conftest.py

```bash
cat /Users/samosipov/Downloads/learn-greek-easy/learn-greek-easy-backend/tests/conftest.py
```

**Note**: Existing conftest.py will be enhanced, not replaced

---

## Step-by-Step Implementation

### STEP 1: Configure Pytest in pyproject.toml

**File to Modify**: `/Users/samosipov/Downloads/learn-greek-easy/learn-greek-easy-backend/pyproject.toml`

**Add the following section** at the end of the file:

```toml
# =============================================================================
# Pytest Configuration
# =============================================================================

[tool.pytest.ini_options]
# Async mode - automatically discover and run async tests
asyncio_mode = "auto"
asyncio_default_fixture_loop_scope = "function"

# Test discovery
testpaths = ["tests"]
python_files = ["test_*.py", "*_test.py"]
python_classes = ["Test*"]
python_functions = ["test_*"]

# Output configuration
addopts = [
    "-v",
    "--tb=short",
    "--strict-markers",
    "-ra",
    "--color=yes",
]

# Test markers
markers = [
    "unit: Unit tests (fast, isolated, mocked dependencies)",
    "integration: Integration tests (slower, real database)",
    "slow: Slow tests (>1s execution time)",
    "auth: Authentication-related tests",
    "api: API endpoint tests",
    "db: Database-related tests",
]

# Async configuration
asyncio_default_fixture_loop_scope = "function"

# Filter warnings for cleaner output
filterwarnings = [
    "ignore::DeprecationWarning",
    "ignore::PendingDeprecationWarning",
    "ignore::pytest.PytestUnraisableExceptionWarning",
    "ignore::pytest.PytestCollectionWarning",
    # SQLAlchemy async warnings
    "ignore:The garbage collector is trying to clean up non-checked-in connection:RuntimeWarning",
]

# Minimum pytest version
minversion = "8.0"

# Fail on unknown markers (catches typos)
# Already enabled via --strict-markers in addopts

# Show local variables in tracebacks (useful for debugging)
# showlocals = true

# Stop after first N failures (useful during development)
# maxfail = 3
```

**Configuration Explanation**:

| Setting | Value | Purpose |
|---------|-------|---------|
| `asyncio_mode` | `"auto"` | Automatically detect async tests, no `@pytest.mark.asyncio` needed |
| `asyncio_default_fixture_loop_scope` | `"function"` | Create new event loop per test function |
| `testpaths` | `["tests"]` | Only look for tests in tests/ directory |
| `addopts` | Various | Default command line options |
| `markers` | Custom markers | Allow filtering tests by category |
| `filterwarnings` | Various | Suppress noisy warnings |
| `minversion` | `"8.0"` | Ensure pytest 8+ is used |

### STEP 2: Create/Update Global conftest.py

**File to Create/Modify**: `/Users/samosipov/Downloads/learn-greek-easy/learn-greek-easy-backend/tests/conftest.py`

**Complete Code** (replace existing content):

```python
"""Global test fixtures and configuration for Learn Greek Easy backend.

This module provides:
- Event loop configuration for async tests
- Pytest plugins and hooks
- Shared fixtures available to all tests
- Test markers registration

Note: Database fixtures are in tests/fixtures/database.py
      Auth fixtures are in tests/fixtures/auth.py
"""

from collections.abc import Generator
from typing import Any

import pytest


# =============================================================================
# Event Loop Configuration
# =============================================================================


@pytest.fixture(scope="session")
def event_loop_policy():
    """Provide event loop policy for the test session.

    Uses the default asyncio event loop policy, which is appropriate for
    most cases. Override this fixture if you need a custom policy.

    Returns:
        asyncio.AbstractEventLoopPolicy: The event loop policy to use.
    """
    import asyncio
    return asyncio.DefaultEventLoopPolicy()


# =============================================================================
# Pytest Configuration Hooks
# =============================================================================


def pytest_configure(config: pytest.Config) -> None:
    """Configure pytest with custom markers and settings.

    This hook runs during pytest's configuration phase, before test collection.
    We use it to:
    - Register custom markers (unit, integration, slow, auth, api, db)
    - Set up any global test configuration

    Args:
        config: The pytest configuration object.
    """
    # Register custom markers (also defined in pyproject.toml for IDE support)
    config.addinivalue_line(
        "markers", "unit: Unit tests (fast, isolated, mocked dependencies)"
    )
    config.addinivalue_line(
        "markers", "integration: Integration tests (slower, real database)"
    )
    config.addinivalue_line(
        "markers", "slow: Slow tests (>1s execution time)"
    )
    config.addinivalue_line(
        "markers", "auth: Authentication-related tests"
    )
    config.addinivalue_line(
        "markers", "api: API endpoint tests"
    )
    config.addinivalue_line(
        "markers", "db: Database-related tests"
    )


def pytest_collection_modifyitems(
    session: pytest.Session,
    config: pytest.Config,
    items: list[pytest.Item],
) -> None:
    """Modify collected test items.

    This hook runs after test collection. We use it to:
    - Auto-mark tests based on their location (unit/ or integration/)
    - Add default markers for test organization

    Args:
        session: The pytest session.
        config: The pytest configuration.
        items: List of collected test items.
    """
    for item in items:
        # Auto-mark tests based on directory
        if "unit/" in str(item.fspath):
            item.add_marker(pytest.mark.unit)
        elif "integration/" in str(item.fspath):
            item.add_marker(pytest.mark.integration)

        # Auto-mark auth-related tests
        if "auth" in item.name.lower() or "auth" in str(item.fspath).lower():
            item.add_marker(pytest.mark.auth)

        # Auto-mark middleware tests
        if "middleware" in str(item.fspath).lower():
            item.add_marker(pytest.mark.unit)


def pytest_report_header(config: pytest.Config) -> list[str]:
    """Add custom information to the pytest report header.

    This appears at the start of the test run output.

    Args:
        config: The pytest configuration.

    Returns:
        List of strings to add to the report header.
    """
    return [
        "Learn Greek Easy Backend Test Suite",
        "Async Mode: auto (pytest-asyncio)",
        "=" * 50,
    ]


# =============================================================================
# Utility Fixtures
# =============================================================================


@pytest.fixture
def anyio_backend() -> str:
    """Specify the async backend for anyio-based tests.

    Returns:
        str: The backend name ("asyncio").
    """
    return "asyncio"


@pytest.fixture
def sample_password() -> str:
    """Provide a sample strong password for testing.

    This password meets all strength requirements:
    - 8+ characters
    - Uppercase and lowercase letters
    - Numbers
    - Special characters

    Returns:
        str: A valid strong password.
    """
    return "TestPassword123!"


@pytest.fixture
def sample_email() -> str:
    """Provide a sample email for testing.

    Returns:
        str: A valid test email address.
    """
    return "test@example.com"


@pytest.fixture
def sample_user_data(sample_email: str, sample_password: str) -> dict[str, Any]:
    """Provide sample user data for registration tests.

    Args:
        sample_email: The email fixture.
        sample_password: The password fixture.

    Returns:
        dict: User registration data.
    """
    return {
        "email": sample_email,
        "password": sample_password,
        "display_name": "Test User",
    }


# =============================================================================
# Test Environment Fixtures
# =============================================================================


@pytest.fixture(scope="session")
def test_settings() -> dict[str, Any]:
    """Provide test environment settings.

    Returns:
        dict: Configuration settings for tests.
    """
    return {
        "testing": True,
        "debug": True,
        "database_url": "sqlite+aiosqlite:///:memory:",
        "jwt_secret": "test-secret-key-for-testing-only",
        "jwt_algorithm": "HS256",
        "access_token_expire_minutes": 30,
        "refresh_token_expire_days": 30,
    }


# =============================================================================
# Async Utility Fixtures
# =============================================================================


@pytest.fixture
async def async_sleep():
    """Provide an async sleep function for timing tests.

    Yields:
        Callable: An async sleep function.
    """
    import asyncio

    async def _sleep(seconds: float) -> None:
        await asyncio.sleep(seconds)

    return _sleep


# =============================================================================
# Cleanup Fixtures
# =============================================================================


@pytest.fixture(autouse=True)
def reset_test_state() -> Generator[None, None, None]:
    """Reset any global test state between tests.

    This fixture runs automatically before and after each test,
    ensuring tests are isolated from each other.

    Yields:
        None: Allows the test to run.
    """
    # Setup: nothing to do yet
    yield
    # Teardown: nothing to do yet (database cleanup handled separately)


# =============================================================================
# Import Fixtures from Submodules (when created)
# =============================================================================

# Note: The following imports will be added as fixtures are created:
# from tests.fixtures.database import db_session, db_engine, test_db
# from tests.fixtures.auth import test_user, test_user_tokens, auth_headers, client
# from tests.factories import UserFactory, DeckFactory, CardFactory
```

### STEP 3: Create Test Directory Structure

**Create the following directories and __init__.py files**:

```bash
# Create directories
mkdir -p /Users/samosipov/Downloads/learn-greek-easy/learn-greek-easy-backend/tests/fixtures
mkdir -p /Users/samosipov/Downloads/learn-greek-easy/learn-greek-easy-backend/tests/factories
mkdir -p /Users/samosipov/Downloads/learn-greek-easy/learn-greek-easy-backend/tests/integration

# Create __init__.py files
touch /Users/samosipov/Downloads/learn-greek-easy/learn-greek-easy-backend/tests/__init__.py
touch /Users/samosipov/Downloads/learn-greek-easy/learn-greek-easy-backend/tests/unit/__init__.py
touch /Users/samosipov/Downloads/learn-greek-easy/learn-greek-easy-backend/tests/fixtures/__init__.py
touch /Users/samosipov/Downloads/learn-greek-easy/learn-greek-easy-backend/tests/factories/__init__.py
touch /Users/samosipov/Downloads/learn-greek-easy/learn-greek-easy-backend/tests/integration/__init__.py
```

**File**: `/Users/samosipov/Downloads/learn-greek-easy/learn-greek-easy-backend/tests/fixtures/__init__.py`

```python
"""Test fixtures package.

This package contains reusable test fixtures:
- database.py: Database session and engine fixtures
- auth.py: Authentication-related fixtures (users, tokens, clients)
- data.py: Test data fixtures

Import fixtures in conftest.py to make them available globally.
"""

# Fixtures will be imported here as they are created
# Example:
# from tests.fixtures.database import db_session, db_engine
# from tests.fixtures.auth import test_user, auth_headers

__all__: list[str] = []
```

**File**: `/Users/samosipov/Downloads/learn-greek-easy/learn-greek-easy-backend/tests/factories/__init__.py`

```python
"""Test factories package.

This package contains factory-boy factories for creating test data:
- user.py: UserFactory, UserSettingsFactory, RefreshTokenFactory
- deck.py: DeckFactory, CardFactory
- progress.py: ProgressFactory, ReviewFactory

Factories generate realistic test data with sensible defaults.

Example usage:
    from tests.factories import UserFactory

    # Create a user
    user = UserFactory()

    # Create a user with specific attributes
    admin_user = UserFactory(is_superuser=True)

    # Create a batch of users
    users = UserFactory.create_batch(10)
"""

# Factories will be imported here as they are created
# Example:
# from tests.factories.user import UserFactory, UserSettingsFactory
# from tests.factories.deck import DeckFactory, CardFactory

__all__: list[str] = []
```

**File**: `/Users/samosipov/Downloads/learn-greek-easy/learn-greek-easy-backend/tests/integration/__init__.py`

```python
"""Integration tests package.

Integration tests verify that multiple components work together correctly.
These tests use a real (test) database and make actual HTTP requests.

Key characteristics:
- Slower than unit tests
- Use real database (SQLite in-memory or PostgreSQL test DB)
- Test complete request/response cycles
- May have dependencies between operations

Run integration tests:
    poetry run pytest tests/integration/ -v

Skip integration tests (run only unit tests):
    poetry run pytest -m "not integration"
"""
```

### STEP 4: Create Async Test Verification Script

**File to Create**: `/Users/samosipov/Downloads/learn-greek-easy/learn-greek-easy-backend/scripts/verify_pytest_async.py`

```python
"""Verify pytest async configuration is working correctly.

This script tests:
1. pytest-asyncio is installed
2. asyncio_mode is set to "auto"
3. Async tests run without @pytest.mark.asyncio decorator
4. Event loop is properly configured
5. Test markers are registered
"""

import subprocess
import sys


def run_command(cmd: list[str]) -> tuple[int, str, str]:
    """Run a command and return exit code, stdout, stderr."""
    result = subprocess.run(cmd, capture_output=True, text=True)
    return result.returncode, result.stdout, result.stderr


def main() -> int:
    """Run all verification checks."""
    print("=" * 70)
    print("PYTEST ASYNC CONFIGURATION VERIFICATION")
    print("=" * 70)
    print()

    all_passed = True

    # Check 1: pytest-asyncio is installed
    print("Check 1: pytest-asyncio installation")
    code, out, err = run_command(["poetry", "show", "pytest-asyncio"])
    if code == 0 and "pytest-asyncio" in out:
        print(f"  [PASS] pytest-asyncio is installed")
        print(f"  Version: {out.split()[1] if len(out.split()) > 1 else 'unknown'}")
    else:
        print(f"  [FAIL] pytest-asyncio not found")
        all_passed = False
    print()

    # Check 2: asyncio_mode is set in pyproject.toml
    print("Check 2: asyncio_mode configuration")
    try:
        with open("pyproject.toml") as f:
            content = f.read()
        if 'asyncio_mode = "auto"' in content:
            print("  [PASS] asyncio_mode = 'auto' is configured")
        else:
            print("  [FAIL] asyncio_mode not set to 'auto' in pyproject.toml")
            all_passed = False
    except FileNotFoundError:
        print("  [FAIL] pyproject.toml not found")
        all_passed = False
    print()

    # Check 3: Test markers are registered
    print("Check 3: Test markers registration")
    code, out, err = run_command(["poetry", "run", "pytest", "--markers"])
    expected_markers = ["unit", "integration", "slow", "auth"]
    for marker in expected_markers:
        if marker in out:
            print(f"  [PASS] Marker '{marker}' is registered")
        else:
            print(f"  [FAIL] Marker '{marker}' not found")
            all_passed = False
    print()

    # Check 4: Collect tests without errors
    print("Check 4: Test collection")
    code, out, err = run_command([
        "poetry", "run", "pytest", "--collect-only", "-q"
    ])
    if code == 0:
        lines = out.strip().split("\n")
        last_line = lines[-1] if lines else ""
        print(f"  [PASS] Test collection successful")
        print(f"  {last_line}")
    else:
        print(f"  [FAIL] Test collection failed")
        print(f"  Error: {err}")
        all_passed = False
    print()

    # Check 5: Run a simple async test
    print("Check 5: Async test execution")
    test_code = '''
import pytest

async def test_async_works():
    """Test that async tests work without decorator."""
    import asyncio
    await asyncio.sleep(0.001)
    assert True

def test_sync_still_works():
    """Test that sync tests still work."""
    assert True
'''

    # Write temporary test file
    import tempfile
    import os

    with tempfile.NamedTemporaryFile(
        mode="w",
        suffix="_test.py",
        dir="tests/unit",
        delete=False
    ) as f:
        f.write(test_code)
        temp_file = f.name

    try:
        code, out, err = run_command([
            "poetry", "run", "pytest", temp_file, "-v"
        ])
        if code == 0 and "2 passed" in out:
            print("  [PASS] Async tests run without @pytest.mark.asyncio")
            print("  [PASS] Sync tests continue to work")
        else:
            print(f"  [FAIL] Test execution failed")
            print(f"  stdout: {out}")
            print(f"  stderr: {err}")
            all_passed = False
    finally:
        os.unlink(temp_file)
    print()

    # Check 6: Verify existing tests still pass
    print("Check 6: Existing tests pass")
    code, out, err = run_command([
        "poetry", "run", "pytest", "tests/unit/test_security.py", "-q"
    ])
    if code == 0 and "passed" in out:
        print("  [PASS] Existing unit tests pass")
        # Extract pass count
        for line in out.split("\n"):
            if "passed" in line:
                print(f"  {line.strip()}")
    else:
        print(f"  [FAIL] Existing tests failed")
        print(f"  {err}")
        all_passed = False
    print()

    # Summary
    print("=" * 70)
    if all_passed:
        print("ALL CHECKS PASSED!")
        print("=" * 70)
        print()
        print("Summary:")
        print("  - pytest-asyncio is properly configured")
        print("  - asyncio_mode = 'auto' is enabled")
        print("  - Test markers are registered")
        print("  - Async tests work without decorators")
        print("  - Existing tests continue to pass")
        print()
        return 0
    else:
        print("SOME CHECKS FAILED!")
        print("=" * 70)
        print()
        print("Please review the failed checks above and fix the configuration.")
        return 1


if __name__ == "__main__":
    sys.exit(main())
```

### STEP 5: Create Sample Async Test

**File to Create**: `/Users/samosipov/Downloads/learn-greek-easy/learn-greek-easy-backend/tests/unit/test_async_config.py`

```python
"""Tests to verify async configuration is working correctly.

These tests verify:
1. Async tests run without @pytest.mark.asyncio decorator
2. Event loop is available in async tests
3. Multiple async tests can run in sequence
4. Async fixtures work correctly
5. Test markers are properly applied
"""

import asyncio
from typing import Any

import pytest


# =============================================================================
# Basic Async Tests (no decorator needed with asyncio_mode="auto")
# =============================================================================


async def test_async_test_runs_without_decorator():
    """Verify async tests run without @pytest.mark.asyncio decorator."""
    await asyncio.sleep(0.001)
    assert True


async def test_async_sleep_works():
    """Verify asyncio.sleep works in tests."""
    start = asyncio.get_event_loop().time()
    await asyncio.sleep(0.01)
    end = asyncio.get_event_loop().time()
    assert end - start >= 0.01


async def test_multiple_awaits():
    """Verify multiple awaits work in a single test."""
    results = []

    async def append_after_delay(value: int, delay: float) -> None:
        await asyncio.sleep(delay)
        results.append(value)

    await append_after_delay(1, 0.001)
    await append_after_delay(2, 0.001)
    await append_after_delay(3, 0.001)

    assert results == [1, 2, 3]


# =============================================================================
# Event Loop Tests
# =============================================================================


async def test_event_loop_is_available():
    """Verify event loop is available in async tests."""
    loop = asyncio.get_event_loop()
    assert loop is not None
    assert loop.is_running()


async def test_event_loop_is_same_within_test():
    """Verify same event loop is used throughout a single test."""
    loop1 = asyncio.get_event_loop()
    await asyncio.sleep(0.001)
    loop2 = asyncio.get_event_loop()
    assert loop1 is loop2


# =============================================================================
# Concurrent Async Operations
# =============================================================================


async def test_gather_works():
    """Verify asyncio.gather works in tests."""
    async def delayed_return(value: int, delay: float) -> int:
        await asyncio.sleep(delay)
        return value

    results = await asyncio.gather(
        delayed_return(1, 0.01),
        delayed_return(2, 0.01),
        delayed_return(3, 0.01),
    )

    assert results == [1, 2, 3]


async def test_create_task_works():
    """Verify asyncio.create_task works in tests."""
    results: list[int] = []

    async def append_value(value: int) -> None:
        await asyncio.sleep(0.001)
        results.append(value)

    task1 = asyncio.create_task(append_value(1))
    task2 = asyncio.create_task(append_value(2))

    await task1
    await task2

    assert sorted(results) == [1, 2]


# =============================================================================
# Async Fixtures Tests
# =============================================================================


@pytest.fixture
async def async_value():
    """Async fixture that provides a value after a delay."""
    await asyncio.sleep(0.001)
    return 42


@pytest.fixture
async def async_context():
    """Async fixture with setup and teardown."""
    # Setup
    data = {"setup": True, "cleaned_up": False}
    await asyncio.sleep(0.001)

    yield data

    # Teardown
    data["cleaned_up"] = True
    await asyncio.sleep(0.001)


async def test_async_fixture_provides_value(async_value: int):
    """Verify async fixtures work correctly."""
    assert async_value == 42


async def test_async_fixture_with_context(async_context: dict[str, Any]):
    """Verify async fixtures with setup/teardown work."""
    assert async_context["setup"] is True
    assert async_context["cleaned_up"] is False  # Not yet


# =============================================================================
# Test Markers
# =============================================================================


@pytest.mark.unit
def test_unit_marker_works():
    """Verify @pytest.mark.unit works."""
    assert True


@pytest.mark.slow
async def test_slow_marker_works():
    """Verify @pytest.mark.slow works with async tests."""
    await asyncio.sleep(0.001)
    assert True


@pytest.mark.auth
async def test_auth_marker_works():
    """Verify @pytest.mark.auth works."""
    await asyncio.sleep(0.001)
    assert True


# =============================================================================
# Sync Tests Still Work
# =============================================================================


def test_sync_test_still_works():
    """Verify sync tests continue to work."""
    assert 1 + 1 == 2


def test_sync_with_assertion():
    """Verify sync tests with assertions work."""
    data = {"key": "value"}
    assert "key" in data
    assert data["key"] == "value"


class TestSyncClass:
    """Verify sync test classes work."""

    def test_method_works(self):
        """Verify sync test methods work."""
        assert True

    def test_with_fixture(self, sample_password: str):
        """Verify sync tests can use fixtures."""
        assert "Password" in sample_password


# =============================================================================
# Mixed Sync/Async Class
# =============================================================================


class TestMixedAsyncSync:
    """Test class with both sync and async tests."""

    def test_sync_method(self):
        """Sync test in mixed class."""
        assert True

    async def test_async_method(self):
        """Async test in mixed class."""
        await asyncio.sleep(0.001)
        assert True

    async def test_async_with_fixture(self, async_value: int):
        """Async test with async fixture in mixed class."""
        assert async_value == 42
```

---

## Testing Instructions

### Test Suite 1: Verify Configuration

Run the verification script:

```bash
cd /Users/samosipov/Downloads/learn-greek-easy/learn-greek-easy-backend && /Users/samosipov/.local/bin/poetry run python scripts/verify_pytest_async.py
```

**Expected Output**: All checks should pass

### Test Suite 2: Run Async Config Tests

```bash
cd /Users/samosipov/Downloads/learn-greek-easy/learn-greek-easy-backend && /Users/samosipov/.local/bin/poetry run pytest tests/unit/test_async_config.py -v
```

**Expected Output**: All tests pass (~20 tests)

### Test Suite 3: Run All Existing Tests

```bash
cd /Users/samosipov/Downloads/learn-greek-easy/learn-greek-easy-backend && /Users/samosipov/.local/bin/poetry run pytest tests/unit/ -v
```

**Expected Output**: All existing tests continue to pass (~149+ tests)

### Test Suite 4: Run Tests by Marker

```bash
# Run only unit tests
cd /Users/samosipov/Downloads/learn-greek-easy/learn-greek-easy-backend && /Users/samosipov/.local/bin/poetry run pytest -m unit -v

# Run only auth tests
cd /Users/samosipov/Downloads/learn-greek-easy/learn-greek-easy-backend && /Users/samosipov/.local/bin/poetry run pytest -m auth -v

# Skip slow tests
cd /Users/samosipov/Downloads/learn-greek-easy/learn-greek-easy-backend && /Users/samosipov/.local/bin/poetry run pytest -m "not slow" -v
```

### Test Suite 5: Show Registered Markers

```bash
cd /Users/samosipov/Downloads/learn-greek-easy/learn-greek-easy-backend && /Users/samosipov/.local/bin/poetry run pytest --markers | head -20
```

**Expected Output**: Should show unit, integration, slow, auth, api, db markers

### Test Suite 6: Run with Verbose Header

```bash
cd /Users/samosipov/Downloads/learn-greek-easy/learn-greek-easy-backend && /Users/samosipov/.local/bin/poetry run pytest tests/unit/test_async_config.py -v 2>&1 | head -10
```

**Expected Output**: Should show custom header "Learn Greek Easy Backend Test Suite"

---

## Validation Checklist

Use this checklist to verify the implementation is complete:

### Configuration Checks
- [ ] `pyproject.toml` has `[tool.pytest.ini_options]` section
- [ ] `asyncio_mode = "auto"` is set
- [ ] `asyncio_default_fixture_loop_scope = "function"` is set
- [ ] `testpaths = ["tests"]` is set
- [ ] All 6 markers are defined (unit, integration, slow, auth, api, db)
- [ ] `filterwarnings` configured to suppress noisy warnings
- [ ] `addopts` includes `-v`, `--tb=short`, `--strict-markers`

### File Structure Checks
- [ ] `tests/conftest.py` updated with event loop and hooks
- [ ] `tests/__init__.py` exists
- [ ] `tests/unit/__init__.py` exists
- [ ] `tests/fixtures/__init__.py` exists
- [ ] `tests/factories/__init__.py` exists
- [ ] `tests/integration/__init__.py` exists
- [ ] `scripts/verify_pytest_async.py` created

### Functionality Checks
- [ ] Async tests run without `@pytest.mark.asyncio` decorator
- [ ] Sync tests continue to work
- [ ] Async fixtures work correctly
- [ ] Test markers can be used for filtering
- [ ] All existing tests (~149) pass
- [ ] New async config tests pass (~20)
- [ ] Verification script passes all checks

### Code Quality Checks
- [ ] No syntax errors in conftest.py
- [ ] All imports resolve correctly
- [ ] Type hints are complete
- [ ] Docstrings follow Google style

---

## Troubleshooting Guide

### Issue 1: "PytestUnknownMarkWarning: Unknown pytest.mark.xxx"

**Cause**: Marker not registered

**Solution**: Ensure markers are defined in both:
1. `pyproject.toml` under `[tool.pytest.ini_options]` markers
2. `conftest.py` in `pytest_configure()` hook

### Issue 2: "Event loop is closed"

**Cause**: Event loop scope mismatch

**Solution**: Set `asyncio_default_fixture_loop_scope = "function"` in pyproject.toml

### Issue 3: "ScopeMismatch: Different scopes for fixture and test"

**Cause**: Session-scoped fixture used in function-scoped test

**Solution**: Ensure fixtures that use the event loop have compatible scopes:
```python
@pytest.fixture(scope="function")  # Not "session"
async def my_fixture():
    ...
```

### Issue 4: "RuntimeWarning: coroutine was never awaited"

**Cause**: Async function called without `await`

**Solution**: Always use `await` when calling async functions:
```python
# Wrong
result = async_function()

# Correct
result = await async_function()
```

### Issue 5: Existing tests fail after configuration change

**Cause**: Breaking change in pytest-asyncio configuration

**Solution**:
1. Check for `@pytest.fixture(scope="module")` fixtures with async
2. Ensure no tests manually create event loops
3. Remove any `@pytest.mark.asyncio` decorators (not needed with auto mode)

### Issue 6: "No tests collected"

**Cause**: Test discovery configuration issue

**Solution**: Verify `testpaths`, `python_files`, `python_functions` in pyproject.toml

### Issue 7: Import errors in conftest.py

**Cause**: Circular imports or missing dependencies

**Solution**:
1. Check all imports are available
2. Use conditional imports for optional dependencies
3. Move imports inside functions if needed

---

## Technical Considerations

### Why asyncio_mode = "auto"?

| Mode | Behavior | When to Use |
|------|----------|-------------|
| `auto` | Automatically detect and run async tests | Modern projects (recommended) |
| `strict` | Require explicit `@pytest.mark.asyncio` | Legacy projects with mixed async |

**Recommendation**: Use `auto` mode for new projects to reduce boilerplate.

### Event Loop Scoping

| Scope | Behavior | Use Case |
|-------|----------|----------|
| `function` | New loop per test | Default, safest |
| `class` | Shared loop per class | Faster, requires care |
| `module` | Shared loop per module | Special cases only |
| `session` | Single loop for all tests | Rarely needed |

**Recommendation**: Use `function` scope for isolation and safety.

### Test Marker Strategy

| Marker | Purpose | Run Command |
|--------|---------|-------------|
| `unit` | Fast, isolated tests | `pytest -m unit` |
| `integration` | DB/API tests | `pytest -m integration` |
| `slow` | Tests > 1s | `pytest -m "not slow"` |
| `auth` | Auth-related | `pytest -m auth` |
| `api` | API endpoint tests | `pytest -m api` |
| `db` | Database tests | `pytest -m db` |

### Performance Considerations

1. **Function-scoped event loops** create overhead but ensure isolation
2. **Auto-marking** in `pytest_collection_modifyitems` has minimal overhead
3. **Warning filters** reduce log noise without affecting functionality

---

## Next Steps

After completing this subtask:

1. **Run verification**:
   ```bash
   cd /Users/samosipov/Downloads/learn-greek-easy/learn-greek-easy-backend && /Users/samosipov/.local/bin/poetry run python scripts/verify_pytest_async.py
   ```

2. **Run all tests**:
   ```bash
   cd /Users/samosipov/Downloads/learn-greek-easy/learn-greek-easy-backend && /Users/samosipov/.local/bin/poetry run pytest tests/ -v
   ```

3. **Proceed to Subtask 04.02**: Setup test database with fixtures
   - Create database fixtures in `tests/fixtures/database.py`
   - Configure SQLite in-memory for fast tests
   - Add PostgreSQL option for integration tests

4. **Update progress tracking**:
   - Mark Subtask 04.01 as COMPLETED
   - Update Backend-Tasks-Progress.md

---

## Quick Reference

### Key Commands

```bash
# Run all tests
cd /Users/samosipov/Downloads/learn-greek-easy/learn-greek-easy-backend && /Users/samosipov/.local/bin/poetry run pytest

# Run with verbose output
cd /Users/samosipov/Downloads/learn-greek-easy/learn-greek-easy-backend && /Users/samosipov/.local/bin/poetry run pytest -v

# Run only unit tests
cd /Users/samosipov/Downloads/learn-greek-easy/learn-greek-easy-backend && /Users/samosipov/.local/bin/poetry run pytest -m unit

# Skip slow tests
cd /Users/samosipov/Downloads/learn-greek-easy/learn-greek-easy-backend && /Users/samosipov/.local/bin/poetry run pytest -m "not slow"

# Show all markers
cd /Users/samosipov/Downloads/learn-greek-easy/learn-greek-easy-backend && /Users/samosipov/.local/bin/poetry run pytest --markers

# Verify configuration
cd /Users/samosipov/Downloads/learn-greek-easy/learn-greek-easy-backend && /Users/samosipov/.local/bin/poetry run python scripts/verify_pytest_async.py
```

### Configuration Locations

| Setting | Location |
|---------|----------|
| Pytest options | `pyproject.toml [tool.pytest.ini_options]` |
| Global fixtures | `tests/conftest.py` |
| Test markers | Both `pyproject.toml` and `conftest.py` |
| Event loop | `tests/conftest.py` (event_loop_policy fixture) |

---

**Document Version**: 1.1
**Created**: 2025-11-29
**Completed**: 2025-11-30
**Author**: Architecture Team
**Status**: ✅ COMPLETED
**Priority**: Critical Path
**Actual Duration**: ~45 minutes
